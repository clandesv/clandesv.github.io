[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Please enjoy exploring my portfolio to learn more about my person and to see a selection of my previous work and projects."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "üëã Greetings! My name is Camille Landesvatter.\nüë©üèΩ‚Äçüíª For the last 3.5 years I have been working as a Quantitative Researcher at the Mannheim Centre for European Social Research (MZES) at the University of Mannheim.\nüè´ I studied Social Sciences and Sociology at the University of Stuttgart and Mannheim. I chose my courses, coursework and thesis within the intersection of survey research, statistics and data science.\nüéì In April 2024 I earned my PhD in Quantitative Sociology at the Department for Social Data Science and Methodology (UMA).\n\nThesis Title: ‚ÄúMethods for the Classification of Data from Open-Ended Questions in Surveys‚Äù\nGPA: 1.5 (Magna Cum Laude)\nüå∞ My PhD in a Nutshell (Disputation Talk): Methods for the Classification of Data from Open-Ended Questions in Surveys\n\nüìç I currently live in Berlin, Germany and soon want to explore another European country.\nüîé I am currently exploring opportunities in Data Analysis and Data Science for my next professional chapter."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "In my previous work and projects, I‚Äôve applied statistical analysis methods, ranging from descriptive techniques to advanced methodologies. One of my focus in advanced methods is Natural Language Processing, where I use methods of machine learning and deep learning techniques to generate knowledge about textual data.\nIn terms of machine learning, I mostly enjoy and appreciate supervised machine learning (Andrew Ng‚Äôs explantion on why these architectures are the most useful), I have also worked in projects successfully utilizing unsupervised techniques (e.g., topic modeling) and large language models (e.g., zero-shot prompting with GPT-3.5).\n\nEntropy analysis\n\nSummary: Questionnaires sometimes include open-ended questions (and if we had better access to methods for analyzing their open-ended responses, we would see them even more often). In this project, I investigated whether open-ended answers are useful in terms of their information content. This research required me to define and to operationalize information content (i.e., the amount of information given in an answer). Among various measures, I proposed the use of a measure from information theory, the entropy of a response. The below figure is my visualization for exemplary survey answers alongside their entropy score.\n\n\n\n\n\nFigure 1: Example Survey Answers by Entropy.Note. The topic ofthis questionnaire item concerned environmental issues.\n\n\n\n\n\nTopic Model Analysis\n\nSummary: Topic Modeling is a widely famous and often used method from unspervised Machine Learning aimin at exploring given topics in a corpus. Throughout my work, I have used topic models at various instances, most often for the usecase of exploring and learning about new, unstructured datasets. I follow the devlopment of topic models since many years, andused various of them (e.g., LDA, BERTopic), but just recently I started working on identifying topics with the help of a Large Language Model. In particular, I use GPT-3.5-turbo and prompt it too identify, label and describe topics in a given corpus. I don‚Äôt provide any examples of topics, hence this is also called zero-shot prompting.\n\nThe below dataset shows the main topics alongside des\n\n\n\n\n\n\n\n\n\n\n\nTopic Name\n\n\nTopic description\n\n\n\n\n\n\nClimate Change Denial\n\n\nSome respondents express skepticism about human-caused climate change and the ability of humans to make a significant impact on the environment.\n\n\n\n\nGlobal Leadership\n\n\nConcerns about the lack of leadership and cooperation among world leaders in addressing climate change.\n\n\n\n\nPollution and Emissions\n\n\nReferences to major polluting countries like China and India, as well as the normalization of pollution.\n\n\n\n\nInequality and Suspicion\n\n\nMentions of inequality among nations and suspicion of other countries‚Äô actions.\n\n\n\n\nCapitalism and Profit Motive\n\n\nDoubts about countries prioritizing profit over environmental safety under capitalism.\n\n\n\n\nInternational Efforts\n\n\nComments on international agreements like the Paris Agreement and the need for global cooperation.\n\n\n\n\nLack of Information\n\n\nAcknowledgment of insufficient information to form a confident opinion on climate change actions.\n\n\n\n\n\n\n\nAutomatic Speech Recognition\n\nSummary: Spoken language provides analysts and researchers with very dense and rich amounts of information. For example speech, in contrast to written language, can deliver additional information through characteristics such as speed, intonation and volume, as well as other non-verbal elements, such as laughter, pauses and sighs. This led me to collect voice answers in various of my survey projects and for one of my white papers I compared different algorithms for automatic speech recognition. In this comparison I find that whisper, a speech-to-text algorithm provided by openAI performs best in terms of word error rates.\n\n\n\n\n\nFigure 2: Waveform of an exemplary audio file and the unit of analyis.\n\n\n\n\n\n\n\nFigure 3: Word Error Rates across different ASR algorithms.\n\n\n\n\n\nFine-tuning of a BERT model to assign open-ended survey answers to pre-defined categories\n\nSummary: The below shows results from one of my research projects in which I investigated various methods of supervised machine learning approaches to assign open-ended survey answers to pre-defined categories. For example, I was interested in detecting whether a certain survey answer is given in positive, negative or neutral sentiment.\n\n\n\n\n\nFigure 4: Sentiment classified with a fine-tuned BERT model for different survey items.\n\n\n\n\n\n\n\nFigure 5: Results from multivariate regression analysis."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "You can also get connected with me here:"
  },
  {
    "objectID": "index.html#you-can-contact-me-here",
    "href": "index.html#you-can-contact-me-here",
    "title": "Welcome!",
    "section": "You can contact me here:",
    "text": "You can contact me here:"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "In my previous work and projects, I‚Äôve applied statistical analysis methods, ranging from descriptive techniques to advanced methodologies. One of my focus in advanced methods is Natural Language Processing, where I use methods of machine learning and deep learning techniques to generate knowledge about textual data.\nIn terms of machine learning, I mostly enjoy and appreciate supervised machine learning (Andrew Ng‚Äôs explantion on why these architectures are the most useful), I have also worked in projects successfully utilizing unsupervised techniques (e.g., topic modeling) and large language models (e.g., zero-shot prompting with GPT-3.5).\n\nEntropy analysis\n\nSummary: Questionnaires sometimes include open-ended questions (and if we had better access to methods for analyzing their open-ended responses, we would see them even more often). In this project, I investigated whether open-ended answers are useful in terms of their information content. This research required me to define and to operationalize information content (i.e., the amount of information given in an answer). Among various measures, I proposed the use of a measure from information theory, the entropy of a response. The below figure is my visualization for exemplary survey answers alongside their entropy score.\n\n\n\n\n\nFigure 1: Example Survey Answers by Entropy.Note. The topic ofthis questionnaire item concerned environmental issues.\n\n\n\n\n\nTopic Model Analysis\n\nSummary: Topic Modeling is a widely famous and often used method from unspervised Machine Learning aimin at exploring given topics in a corpus. Throughout my work, I have used topic models at various instances, most often for the usecase of exploring and learning about new, unstructured datasets. I follow the devlopment of topic models since many years, andused various of them (e.g., LDA, BERTopic), but just recently I started working on identifying topics with the help of a Large Language Model. In particular, I use GPT-3.5-turbo and prompt it too identify, label and describe topics in a given corpus. I don‚Äôt provide any examples of topics, hence this is also called zero-shot prompting.\n\nThe below dataset shows the main topics alongside des\n\n\n\n\n\n\n\n\n\n\n\nTopic Name\n\n\nTopic description\n\n\n\n\n\n\nClimate Change Denial\n\n\nSome respondents express skepticism about human-caused climate change and the ability of humans to make a significant impact on the environment.\n\n\n\n\nGlobal Leadership\n\n\nConcerns about the lack of leadership and cooperation among world leaders in addressing climate change.\n\n\n\n\nPollution and Emissions\n\n\nReferences to major polluting countries like China and India, as well as the normalization of pollution.\n\n\n\n\nInequality and Suspicion\n\n\nMentions of inequality among nations and suspicion of other countries‚Äô actions.\n\n\n\n\nCapitalism and Profit Motive\n\n\nDoubts about countries prioritizing profit over environmental safety under capitalism.\n\n\n\n\nInternational Efforts\n\n\nComments on international agreements like the Paris Agreement and the need for global cooperation.\n\n\n\n\nLack of Information\n\n\nAcknowledgment of insufficient information to form a confident opinion on climate change actions.\n\n\n\n\n\n\n\nAutomatic Speech Recognition\n\nSummary: Spoken language provides analysts and researchers with very dense and rich amounts of information. For example speech, in contrast to written language, can deliver additional information through characteristics such as speed, intonation and volume, as well as other non-verbal elements, such as laughter, pauses and sighs. This led me to collect voice answers in various of my survey projects and for one of my white papers I compared different algorithms for automatic speech recognition. In this comparison I find that whisper, a speech-to-text algorithm provided by openAI performs best in terms of word error rates.\n\n\n\n\n\nFigure 2: Waveform of an exemplary audio file and the unit of analyis.\n\n\n\n\n\n\n\nFigure 3: Word Error Rates across different ASR algorithms.\n\n\n\n\n\nFine-tuning of a BERT model to assign open-ended survey answers to pre-defined categories\n\nSummary: The below shows results from one of my research projects in which I investigated various methods of supervised machine learning approaches to assign open-ended survey answers to pre-defined categories. For example, I was interested in detecting whether a certain survey answer is given in positive, negative or neutral sentiment.\n\n\n\n\n\nFigure 4: Sentiment classified with a fine-tuned BERT model for different survey items.\n\n\n\n\n\n\n\nFigure 5: Results from multivariate regression analysis."
  }
]